{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CICIDS2017 Data Exploration and Graph Construction\n",
    "## Phase 1: Understanding the Data and Building Initial Graphs\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading and exploring CICIDS2017 dataset\n",
    "2. Preprocessing network flow data\n",
    "3. Constructing graph representations\n",
    "4. Visualizing network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import torch\n",
    "\n",
    "# Import custom modules (make sure these files are in src/ directory)\n",
    "from preprocessing.cicids_loader import CICIDS2017Loader\n",
    "from preprocessing.graph_constructor import CyberGraphConstructor\n",
    "\n",
    "# Setup plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore Data\n",
    "\n",
    "**Note**: Update the `data_dir` path to point to your CICIDS2017 CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "loader = CICIDS2017Loader(data_dir=\"../data/raw/CICIDS2017\")\n",
    "\n",
    "# Load and preprocess data (using sample for testing - remove sample_size for full data)\n",
    "df = loader.preprocess_pipeline(sample_size=50000)\n",
    "\n",
    "# Display basic info\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset statistics\n",
    "stats = loader.get_statistics()\n",
    "\n",
    "print(\"=== Dataset Statistics ===\")\n",
    "for key, value in stats.items():\n",
    "    if key != 'label_distribution':\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nLabel Distribution:\")\n",
    "for label, count in stats['label_distribution'].items():\n",
    "    print(f\"  {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Visualize Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot attack vs benign distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Binary classification\n",
    "attack_counts = df['is_attack'].value_counts()\n",
    "axes[0].bar(['Benign', 'Attack'], attack_counts.values, color=['green', 'red'], alpha=0.7)\n",
    "axes[0].set_title('Binary Classification Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Multi-class distribution (top 10)\n",
    "top_labels = df['label_encoded'].value_counts().head(10)\n",
    "axes[1].barh(range(len(top_labels)), top_labels.values)\n",
    "axes[1].set_yticks(range(len(top_labels)))\n",
    "axes[1].set_yticklabels(top_labels.index)\n",
    "axes[1].set_title('Top 10 Attack Types')\n",
    "axes[1].set_xlabel('Count (log scale)')\n",
    "axes[1].set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/data_distribution.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze flow characteristics\n",
    "numeric_cols = ['flow_duration', 'fwd_packets', 'bwd_packets', 'flow_bytes_per_sec']\n",
    "available_cols = [col for col in numeric_cols if col in df.columns]\n",
    "\n",
    "if available_cols:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, col in enumerate(available_cols[:4]):\n",
    "        # Compare benign vs attack\n",
    "        benign = df[df['is_attack'] == 0][col].dropna()\n",
    "        attack = df[df['is_attack'] == 1][col].dropna()\n",
    "        \n",
    "        axes[i].hist(benign, bins=50, alpha=0.5, label='Benign', color='green', density=True)\n",
    "        axes[i].hist(attack, bins=50, alpha=0.5, label='Attack', color='red', density=True)\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Density')\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].legend()\n",
    "        axes[i].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../results/visualizations/flow_characteristics.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Construct Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph constructor\n",
    "constructor = CyberGraphConstructor(time_window=300)\n",
    "\n",
    "# Build NetworkX graph\n",
    "print(\"Building graph from network flows...\")\n",
    "G = constructor.build_graph_from_flows(df, directed=True, aggregate=True)\n",
    "\n",
    "print(f\"\\n=== Graph Summary ===\")\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "print(f\"Average degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")\n",
    "print(f\"Graph density: {nx.density(G):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze graph properties\n",
    "degrees = dict(G.degree())\n",
    "attack_ratios = nx.get_node_attributes(G, 'attack_ratio')\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Degree distribution\n",
    "axes[0].hist(list(degrees.values()), bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Degree')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Node Degree Distribution')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Attack ratio distribution\n",
    "axes[1].hist(list(attack_ratios.values()), bins=50, edgecolor='black', alpha=0.7, color='red')\n",
    "axes[1].set_xlabel('Attack Ratio')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Node Attack Ratio Distribution')\n",
    "\n",
    "# Degree vs Attack Ratio\n",
    "deg_vals = [degrees[n] for n in attack_ratios.keys()]\n",
    "att_vals = list(attack_ratios.values())\n",
    "axes[2].scatter(deg_vals, att_vals, alpha=0.3)\n",
    "axes[2].set_xlabel('Node Degree')\n",
    "axes[2].set_ylabel('Attack Ratio')\n",
    "axes[2].set_title('Degree vs Attack Involvement')\n",
    "axes[2].set_xscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/visualizations/graph_properties.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Convert to PyTorch Geometric Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch Geometric Data object\n",
    "pyg_data = constructor.networkx_to_pyg(G)\n",
    "\n",
    "print(\"=== PyTorch Geometric Data ===\")\n",
    "print(f\"Number of nodes: {pyg_data.num_nodes}\")\n",
    "print(f\"Number of edges: {pyg_data.num_edges}\")\n",
    "print(f\"Node feature matrix shape: {pyg_data.x.shape}\")\n",
    "print(f\"Edge feature matrix shape: {pyg_data.edge_attr.shape}\")\n",
    "print(f\"Edge index shape: {pyg_data.edge_index.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(f\"  Benign nodes: {(pyg_data.y == 0).sum().item()}\")\n",
    "print(f\"  Malicious nodes: {(pyg_data.y == 1).sum().item()}\")\n",
    "print(f\"  Class imbalance ratio: {(pyg_data.y == 1).sum().item() / (pyg_data.y == 0).sum().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Graph Structure (Small Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a small subgraph\n",
    "if G.number_of_nodes() > 50:\n",
    "    # Sample high-degree nodes (likely important)\n",
    "    top_nodes = sorted(degrees, key=degrees.get, reverse=True)[:50]\n",
    "    G_sub = G.subgraph(top_nodes)\n",
    "else:\n",
    "    G_sub = G\n",
    "\n",
    "constructor.visualize_graph(G_sub, \n",
    "                           output_path='../results/visualizations/network_graph_sample.png',\n",
    "                           highlight_attacks=True)\n",
    "\n",
    "print(\"Graph visualization saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Processed Data and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed DataFrame\n",
    "df.to_csv('../data/processed/cicids2017_processed.csv', index=False)\n",
    "print(\"Processed data saved to: data/processed/cicids2017_processed.csv\")\n",
    "\n",
    "# Save NetworkX graph\n",
    "constructor.save_graph(G, '../data/graphs/cicids_graph.gpickle')\n",
    "print(\"NetworkX graph saved to: data/graphs/cicids_graph.gpickle\")\n",
    "\n",
    "# Save PyTorch Geometric data\n",
    "torch.save(pyg_data, '../data/graphs/cicids_pyg_data.pt')\n",
    "print(\"PyTorch Geometric data saved to: data/graphs/cicids_pyg_data.pt\")\n",
    "\n",
    "print(\"\\nâœ… All data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Summary Statistics and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Project Status Summary ===\")\n",
    "print(f\"âœ… Dataset loaded and preprocessed: {len(df)} records\")\n",
    "print(f\"âœ… Graph constructed: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "print(f\"âœ… PyTorch Geometric format ready for GNN training\")\n",
    "print(f\"âœ… Visualizations created\")\n",
    "print(\"\\n=== Next Steps ===\")\n",
    "print(\"1. Design GNN architecture (GCN, GAT, or GraphSAGE)\")\n",
    "print(\"2. Implement training pipeline\")\n",
    "print(\"3. Define evaluation metrics\")\n",
    "print(\"4. Train initial baseline model\")\n",
    "print(\"5. Hyperparameter tuning\")\n",
    "print(\"\\nReady to move to Phase 2: Model Development! ðŸš€\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
